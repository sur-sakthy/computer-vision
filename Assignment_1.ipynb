{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ABEzVAWI5eS3"
      ],
      "mount_file_id": "1FCmz1FvudVnEjvqD0XItgtetbAT8y8xl",
      "authorship_tag": "ABX9TyOt/bTqiBw42hwSxBQsq2OJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sur-sakthy/computer-vision/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment #1\n",
        "The provided data has a train/validation split of 1000/500 (approx.) images. In this task you are to select any 4 classes from the original ImageNette data as your working dataset (i.e. classification whereby you are predicting one of four possible classes).\n",
        "\n",
        "Additionally, you need to reorganise the data into appropriate train/validation/test split before you train your network models. The details of the splitting is left to you, but you must fully justify any final split used in your evaluation."
      ],
      "metadata": {
        "id": "WTJaiwHQzzNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxps2ylf50SH",
        "outputId": "fc34a9fa-2b7c-4c01-d7db-5ec6ab23e903"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zq-MwcjOzETs"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/EE544 Computer Vision/imagenette2-160.tgz' ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove %%capture command to show output from unzipping\n",
        "%%capture \n",
        "!tar zxvf /content/imagenette2-160.tgz"
      ],
      "metadata": {
        "id": "79KjQJxnAgCv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "mvvEa4-OLaTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, AUC, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "-4ONl5dQGvub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "SNw6u_X4Vjhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_TRAIN_DATA = '/content/imagenette2-160/train'\n",
        "PATH_TO_VAL_DATA = '/content/imagenette2-160/val'\n",
        "IMG_WIDTH=64\n",
        "IMG_HEIGHT=64\n",
        "NUM_CLASSES=4"
      ],
      "metadata": {
        "id": "Mqij7Db_GdEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes = os.listdir(PATH_TO_TRAIN_DATA)\n",
        "all_classes"
      ],
      "metadata": {
        "id": "blZUoPmqGmuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes = os.listdir(PATH_TO_VAL_DATA)\n",
        "all_classes"
      ],
      "metadata": {
        "id": "vJ7YtI7zHS5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "GAPRTpueQCQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "M04-MyRHnivw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(img_folder): \n",
        "    for dir in os.listdir(img_folder):\n",
        "      if dir == 'n03445777' or dir == 'n03417042' or dir == 'n02979186' or dir == 'n03028079' :\n",
        "        for file in os.listdir(os.path.join(img_folder, dir)):\n",
        "            image_path = os.path.join(img_folder, dir, file)\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(64,64))\n",
        "            input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            input_arr = np.array([input_arr])\n",
        "            image = np.array(image)\n",
        "            data.append(image)\n",
        "            labels.append(dir)"
      ],
      "metadata": {
        "id": "aPu_wDteHj7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dataset(PATH_TO_TRAIN_DATA)\n",
        "load_dataset(PATH_TO_VAL_DATA)"
      ],
      "metadata": {
        "id": "FWqY1YqYmBw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels)"
      ],
      "metadata": {
        "id": "1KtBUddwMf7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "9frhu7uaNGqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffle and split"
      ],
      "metadata": {
        "id": "fiEa6VN9QEVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.30, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "wkQrikB6q9LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class distribution"
      ],
      "metadata": {
        "id": "aw2IBtfFP8YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(y_train, columns=['label'])\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "p6O6bXLwOptx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df_train, x='label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dqdcinbjO4hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.DataFrame(y_test, columns=['label'])\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "zUJ5K75XPCxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df_test, x='label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dgLwhFaQPMtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pd.DataFrame(y_val, columns=['label'])\n",
        "df_val.head()"
      ],
      "metadata": {
        "id": "Ffya_-TJKuHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df_val, x='label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zKybFqldKuFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "k3-odDC4P4iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(y, num_classes):\n",
        "  le = LabelEncoder()\n",
        "  return to_categorical(le.fit_transform(y), num_classes)"
      ],
      "metadata": {
        "id": "j05-94gsVG7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "id": "TIIs6vhcPSlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = one_hot_encode(y_train, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "BPYfBPPNPXhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "id": "t7fvDvpkPm04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "metadata": {
        "id": "dT7y2i_1PtcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = one_hot_encode(y_test, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "q302nQhQPtWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "metadata": {
        "id": "xFJEn4BOPtPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_train).shape"
      ],
      "metadata": {
        "id": "8BglGxUPeelq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val[0]"
      ],
      "metadata": {
        "id": "mDS2VaEgJEQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = one_hot_encode(y_val, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "niF9uj0WJHR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val"
      ],
      "metadata": {
        "id": "QoFFPvuzJHNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create train, validation and test sets"
      ],
      "metadata": {
        "id": "L9lbpcv7QZYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(        \n",
        "        rescale=1./255,\n",
        "        fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "QAmBWWzTQLfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_datagen.flow(\n",
        "  np.array(X_train), y_train,\n",
        "  shuffle=True,\n",
        "  batch_size=128\n",
        ")\n",
        "\n",
        "val_ds = train_datagen.flow(\n",
        "  np.array(X_val), y_val,\n",
        "  shuffle=True,\n",
        "  batch_size=128\n",
        ")\n",
        "\n",
        "test_ds = test_datagen.flow(\n",
        "  np.array(X_test), y_test,\n",
        "  shuffle=False,\n",
        "  batch_size=128\n",
        ")"
      ],
      "metadata": {
        "id": "DEGRrcKyQLR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training samples: ', train_ds.x.shape)\n",
        "print('Shape of validation samples: ', val_ds.x.shape)\n",
        "print('Shape of test samples: ', test_ds.x.shape)"
      ],
      "metadata": {
        "id": "TWpxTK2fUMbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model"
      ],
      "metadata": {
        "id": "mXM62rqgWnmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(batchNorm=False, dropOut=False, l2Reg=False):\n",
        "  model = Sequential()\n",
        "\n",
        "  if l2Reg:\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu', kernel_regularizer='l2', input_shape=(64,64,3)))\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu', kernel_regularizer='l2'))\n",
        "  else:\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(64,64,3)))\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "  \n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  if batchNorm:\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "  if l2Reg:\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', kernel_regularizer='l2'))\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', kernel_regularizer='l2'))\n",
        "  else:\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "  \n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  if batchNorm:\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  if l2Reg:\n",
        "    model.add(Dense(512, kernel_regularizer='l2'))\n",
        "  else:\n",
        "    model.add(Dense(512))\n",
        "  \n",
        "  if dropOut:\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "  if l2Reg:\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer='l2'))\n",
        "  else:\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=Adam(),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=[\n",
        "          CategoricalAccuracy(),\n",
        "          Precision(), \n",
        "          Recall(),\n",
        "          AUC()\n",
        "        ]\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zZSDjLoRQA6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rQDGOVCVsKF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "Rm888aZjWquk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialise callbacks"
      ],
      "metadata": {
        "id": "pBeBZRTUPMsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=20)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/EE544 Computer Vision/task-1-best-weights.hdf5', verbose=1, save_best_only=True, monitor='val_categorical_accuracy')"
      ],
      "metadata": {
        "id": "KF2Jfe0ZOn52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model"
      ],
      "metadata": {
        "id": "fxsKgdiyeDSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "1_jktE3JsRBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot results"
      ],
      "metadata": {
        "id": "ob_QDshaYEg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(train, validation, ylabel, title):\n",
        "  plt.plot(train, color='red', label='train') \n",
        "  plt.plot(validation, color='blue', label='validation') \n",
        "  plt.title(title) \n",
        "  plt.ylabel(ylabel)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend() \n",
        "  plt.grid(linestyle='-', linewidth=0.5)"
      ],
      "metadata": {
        "id": "o0jwjfdCWFBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], 'Accuracy', 'Model Accuracy')"
      ],
      "metadata": {
        "id": "lf9pjTVLvvnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history.history['loss'], history.history['val_loss'], 'Loss', 'Model Loss')"
      ],
      "metadata": {
        "id": "DZ92wFIE5dKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "ABEzVAWI5eS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = model.evaluate(test_ds, batch_size=30)"
      ],
      "metadata": {
        "id": "KM66wgM-_kFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test loss:', eval_results[0])\n",
        "print('Test categorical_accuracy:', eval_results[1])\n",
        "print('Test precision:', eval_results[2])\n",
        "print('Test recall:', eval_results[3])\n",
        "print('Test auc:', eval_results[4])"
      ],
      "metadata": {
        "id": "dee871Dgejub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_ds)"
      ],
      "metadata": {
        "id": "MXlcTB3WaoP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "cHZnvE2bdwKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_confusion_matrix(true, pred):\n",
        "  cm = confusion_matrix(true.argmax(axis=1), pred.argmax(axis=1))\n",
        "  sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}, fmt='g', cbar=False, cmap=\"viridis\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "xfqXMoX8b-qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_confusion_matrix(y_test, pred)"
      ],
      "metadata": {
        "id": "0mboVB4q6vYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.argmax(axis=1), pred.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "Xw_nLMYxcQok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve the baseline networks performance\n",
        "1. Batch Normalisation \n",
        "2. Dropout \n",
        "3. Regularisation"
      ],
      "metadata": {
        "id": "lVlp3SN17Guq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Normalisation"
      ],
      "metadata": {
        "id": "SGTQShLWzPE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_model = build_model(batchNorm=True)\n",
        "batchnorm_model.summary()"
      ],
      "metadata": {
        "id": "T1u-7J57yw-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_history = batchnorm_model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds\n",
        ")"
      ],
      "metadata": {
        "id": "IImVU9wOy6Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(batchnorm_history.history['categorical_accuracy'], batchnorm_history.history['val_categorical_accuracy'], 'Accuracy', 'Model Accuracy')"
      ],
      "metadata": {
        "id": "DIc9bm0izCNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(batchnorm_history.history['loss'], batchnorm_history.history['val_loss'], 'Loss', 'Model Loss')"
      ],
      "metadata": {
        "id": "S_G91_ApzKfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout"
      ],
      "metadata": {
        "id": "jDe7i48f3zqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_model = build_model(dropOut=True)\n",
        "dropout_model.summary()"
      ],
      "metadata": {
        "id": "z6SkEvrs7Lhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_history = dropout_model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds\n",
        ")"
      ],
      "metadata": {
        "id": "a7HVKI287gVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(dropout_history.history['categorical_accuracy'], dropout_history.history['val_categorical_accuracy'], 'Accuracy', 'Model Accuracy')"
      ],
      "metadata": {
        "id": "4WZO5i6q7y7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(dropout_history.history['loss'], dropout_history.history['val_loss'], 'Loss', 'Model Loss')"
      ],
      "metadata": {
        "id": "hWTtZL5yzK_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L2 Regularisation"
      ],
      "metadata": {
        "id": "Emf39YOx32p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l2reg_model = build_model(l2Reg=True)\n",
        "l2reg_model.summary()"
      ],
      "metadata": {
        "id": "79KbFJ7k356q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2reg_history = l2reg_model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds\n",
        ")"
      ],
      "metadata": {
        "id": "_dO1Knbq4B0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(l2reg_history.history['categorical_accuracy'], l2reg_history.history['val_categorical_accuracy'], 'Accuracy', 'Model Accuracy')"
      ],
      "metadata": {
        "id": "vcOu4OOq4Cyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(l2reg_history.history['loss'], l2reg_history.history['val_loss'], 'Loss', 'Model Loss')"
      ],
      "metadata": {
        "id": "MIfXc1rP9FBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GpJySw539I4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}