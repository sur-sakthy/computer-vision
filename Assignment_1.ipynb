{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FCmz1FvudVnEjvqD0XItgtetbAT8y8xl",
      "authorship_tag": "ABX9TyPEo/XTcEhiOWKli2piZ7W8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sur-sakthy/computer-vision/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "The provided data has a train/validation split of 1000/500 (approx.) images. In this task you are to select any 4 classes from the original ImageNette data as your working dataset (i.e. classification whereby you are predicting one of four possible classes).\n",
        "\n",
        "Additionally, you need to reorganise the data into appropriate train/validation/test split before you train your network models. The details of the splitting is left to you, but you must fully justify any final split used in your evaluation."
      ],
      "metadata": {
        "id": "WTJaiwHQzzNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zq-MwcjOzETs"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/EE544 Computer Vision/imagenette2-160.tgz' ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar zxvf /content/imagenette2-160.tgz"
      ],
      "metadata": {
        "id": "79KjQJxnAgCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, AUC, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-4ONl5dQGvub"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_TRAIN_DATA = '/content/imagenette2-160/train'\n",
        "PATH_TO_VAL_DATA = '/content/imagenette2-160/val'\n",
        "IMG_WIDTH=64\n",
        "IMG_HEIGHT=64"
      ],
      "metadata": {
        "id": "Mqij7Db_GdEO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes = os.listdir(PATH_TO_TRAIN_DATA)\n",
        "all_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blZUoPmqGmuC",
        "outputId": "3ee752e1-b85b-4bae-8589-75420b74106e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n03445777',\n",
              " 'n03417042',\n",
              " 'n02979186',\n",
              " 'n03028079',\n",
              " 'n03394916',\n",
              " 'n03425413',\n",
              " 'n03888257',\n",
              " '.DS_Store',\n",
              " 'n02102040',\n",
              " 'n03000684',\n",
              " 'n01440764']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes = os.listdir(PATH_TO_VAL_DATA)\n",
        "all_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ7YtI7zHS5U",
        "outputId": "77f1e030-a835-4968-9aff-d51457cd0488"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n03445777',\n",
              " 'n03417042',\n",
              " 'n02979186',\n",
              " 'n03028079',\n",
              " 'n03394916',\n",
              " 'n03425413',\n",
              " 'n03888257',\n",
              " 'n02102040',\n",
              " 'n03000684',\n",
              " 'n01440764']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_array = []\n",
        "class_name = []"
      ],
      "metadata": {
        "id": "M04-MyRHnivw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(img_folder): \n",
        "    for dir in os.listdir(img_folder):\n",
        "      if dir == 'n03445777' or dir == 'n03417042' or dir == 'n02979186' or dir == 'n03028079' :\n",
        "        for file in os.listdir(os.path.join(img_folder, dir)):\n",
        "       \n",
        "            image_path = os.path.join(img_folder, dir, file)\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
        "            image = np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir)"
      ],
      "metadata": {
        "id": "aPu_wDteHj7O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dataset(PATH_TO_TRAIN_DATA)\n",
        "load_dataset(PATH_TO_VAL_DATA)"
      ],
      "metadata": {
        "id": "FWqY1YqYmBw3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(img_data_array, class_name, test_size=0.30, random_state=42)"
      ],
      "metadata": {
        "id": "wkQrikB6q9LO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "cVgLk_Sd6jNB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict = { k: v for v, k in enumerate(np.unique(y_train)) }\n",
        "target_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCEiBST2uzk-",
        "outputId": "bdc85e8e-c7b6-48bc-ce0d-e36174032f30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n02979186': 0, 'n03028079': 1, 'n03417042': 2, 'n03445777': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_target_val(target_dict, target_data):\n",
        "  return [ target_dict[target_data[i]] for i in range(len(target_data)) ]"
      ],
      "metadata": {
        "id": "yIWPp_Oa5PYC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(64,64,3)))\n",
        "  model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=Adam(),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=[\n",
        "          CategoricalAccuracy(),\n",
        "          Precision(), \n",
        "          Recall(),\n",
        "          AUC()\n",
        "        ]\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zZSDjLoRQA6o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQDGOVCVsKF8",
        "outputId": "0d9bec58-6f9c-48c3-d4f0-027e8ffe1e5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10816)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               5538304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,604,385\n",
            "Trainable params: 5,604,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=tf.cast(np.array(X_train), tf.float64), \n",
        "    y=tf.cast(list(map(int, get_target_val(target_dict, y_train))), tf.int32), \n",
        "    epochs=2,\n",
        "    validation_data=(\n",
        "        tf.cast(np.array(X_val), tf.float64), \n",
        "        tf.cast(list(map(int, get_target_val(target_dict, y_val))), tf.int32)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_jktE3JsRBS",
        "outputId": "de8ab645-30b8-475a-f9f0-adaccd1802f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "119/119 [==============================] - 92s 758ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - precision: 0.7444 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000 - val_precision: 0.7776 - val_recall: 1.0000 - val_auc: 0.5000\n",
            "Epoch 2/2\n",
            "119/119 [==============================] - 84s 704ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - precision: 0.7444 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 1.0000 - val_precision: 0.7776 - val_recall: 1.0000 - val_auc: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/EE544 Computer Vision/task #1.h5')"
      ],
      "metadata": {
        "id": "9HhLXk3wDaxq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train accuracy and validation accuracy on the same plot using matplotlob\n",
        "plt.plot(history.history['categorical_accuracy']) \n",
        "plt.plot(history.history['val_categorical_accuracy']) \n",
        "plt.title('Model Accuracy') \n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right') \n",
        "plt.grid(linestyle='-', linewidth=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lf9pjTVLvvnq",
        "outputId": "1e7af205-55f2-46c5-84f7-7a54ae865a14"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KM66wgM-_kFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}